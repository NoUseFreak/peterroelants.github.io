{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to implement a neural network: Part 4\n",
    "\n",
    "This is the fourth part of a 4 (+2) parts tutorial on how to implement a simple neural network model. You can find the links to the rest of the tutorial here:\n",
    "\n",
    "* [Part 1: Linear regression](http://peterroelants.github.io/posts/neural_network_implementation_part01/)\n",
    "* [Intermezzo 1: Logistic classification function](http://peterroelants.github.io/posts/neural_network_implementation_intermezzo01/)\n",
    "* [Part 2: Logistic regression (classification)](http://peterroelants.github.io/posts/neural_network_implementation_part02/)\n",
    "* [Part 3: Hidden layer](http://peterroelants.github.io/posts/neural_network_implementation_part03/)\n",
    "* [Intermezzo 2: Softmax classification function](http://peterroelants.github.io/posts/neural_network_implementation_intermezzo02/)\n",
    "* [Part 4: Vectorization](http://peterroelants.github.io/posts/neural_network_implementation_part04/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization\n",
    "\n",
    "The previous tutorial described a very simple neural network with only one input, one hidden neuron and one output. This tutorial will describe a neural network that takes 2-dimensional input samples, projects them onto a 3-dimensional hidden layer, and classifies them with a 2-dimensional [softmax](http://en.wikipedia.org/wiki/Softmax_function) output classfier, this softmax is explained in [intermezzo 2]({% post_url 2015-06-10-neural_network_implementation_intermezzo02 %}). While we didn't add the bias parameters to the previous 2 models, we will add them to this model. We will work out the vector computations needed to optimize and run this neural network in this tutorial. The network of this model is shown in the following figure:\n",
    "\n",
    "![Image of the neural network](https://dl.dropboxusercontent.com/u/8938051/Blog_images/SimpleANN04.png)\n",
    "\n",
    "The notebook starts out with importing the libraries we need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Python imports\n",
    "import numpy as np # Matrix and vector computation package\n",
    "import matplotlib.pyplot as plt  # Plotting library\n",
    "from matplotlib.colors import colorConverter, ListedColormap # some plotting functions\n",
    "from mpl_toolkits.mplot3d import Axes3D  # 3D plots\n",
    "from matplotlib import cm # Colormaps\n",
    "# Allow matplotlib to plot inside this notebook\n",
    "%matplotlib inline\n",
    "# Set the seed of the numpy random number generator so that the tutorial is reproducable\n",
    "np.random.seed(seed=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the dataset \n",
    "\n",
    "In this example the target classes $t$ corresponding to the inputs $x$ will be generated from 2 class distributions: blue ($t=1$) and red ($t=0$). Where the red class is a circular distribution that surrounds the distribution of the blue class. This results in a 2D dataset that is not linearly seperable. The model from [part 2]({% post_url 2015-06-10-neural_network_implementation_part02 %}) won't be able to classify both classes correctly since it can learn only linear seperators. By adding a hidden layer the model will be able to train a non-linear seperator.\n",
    "\n",
    "The $N$ input samples with $2$ variables each are given as a $N \\times 2$ matrix $X$:\n",
    "\n",
    "$$X =\n",
    "\\begin{bmatrix} \n",
    "x_{11} & x_{12} \\\\\n",
    "\\vdots & \\vdots \\\\\n",
    "x_{N1} & x_{N2}\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "Where $x_{ij}$ is the value of the $j$-th variable of the $i$-th input sample.\n",
    "\n",
    "Since the softmax output function is used the targets for each input sample are given as a $N \\times 2$ matrix $T$:\n",
    "\n",
    "$$T = \\begin{bmatrix} \n",
    "t_{11} & t_{12}\\\\\n",
    "\\vdots & \\vdots \\\\\n",
    "t_{N1} & t_{N2} \n",
    "\\end{bmatrix}$$\n",
    "\n",
    "Where $t_{ij} = 1$ if and only if the $i$-th input sample belongs to class $j$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define and generate the samples\n",
    "nb_of_samples_per_class = 50  # The number of sample in each class\n",
    "\n",
    "# Generate blue samples\n",
    "blue_mean = [0,0]  # The mean of the blue class\n",
    "blue_std_dev = 0.3  # standard deviation of blue class\n",
    "x_blue = np.random.randn(nb_of_samples_per_class, 2) * blue_std_dev + blue_mean\n",
    "\n",
    "# Generate red samples as circle around blue samples\n",
    "red_radius_mean = 1.3  # mean of the radius\n",
    "red_radius_std_dev = 0.2  # standard deviation of the radius\n",
    "red_rand_radius = np.random.randn(nb_of_samples_per_class) * red_radius_std_dev + red_radius_mean\n",
    "red_rand_angle = 2 * np.pi * np.random.rand(nb_of_samples_per_class);\n",
    "x_red = np.asmatrix([red_rand_radius * np.cos(red_rand_angle), \n",
    "                     red_rand_radius * np.sin(red_rand_angle)]).T\n",
    "\n",
    "# Define target vectors for blue and red\n",
    "t_blue_vector = np.asarray([1, 0])\n",
    "t_red_vector = np.asarray([0, 1])\n",
    "# Define the full target matrix for each class\n",
    "t_blue = np.tile(t_blue_vector, (nb_of_samples_per_class, 1))\n",
    "t_red = np.tile(t_red_vector, (nb_of_samples_per_class, 1))\n",
    "\n",
    "# Merge samples in set of input variables x, and corresponding set of\n",
    "# output variables t\n",
    "X = np.vstack((x_blue, x_red))\n",
    "T = np.vstack((t_blue, t_red))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot both classes on the x1, x2 plane\n",
    "plt.plot(x_red[:,0], x_red[:,1], 'ro', label='class red')\n",
    "plt.plot(x_blue[:,0], x_blue[:,1], 'bo', label='class blue')\n",
    "plt.grid()\n",
    "plt.legend(loc=2)\n",
    "plt.xlabel('$x_1$', fontsize=15)\n",
    "plt.ylabel('$x_2$', fontsize=15)\n",
    "plt.axis([-2, 2, -2, 2])\n",
    "plt.title('red vs blue classes in the input space')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization of backpropagation\n",
    "\n",
    "### 1. Vectorization of the forward step\n",
    "\n",
    "#### Compute activations of hidden layer\n",
    "The 2-dimensional inputs $X$ are projected onto the 3 dimensions of the hidden layer $H$ by the weight matrix $W_h$ ($w_{hij}$ is the weight of the connection between input variable $i$ and hidden neuron activation $j$) and bias vector $\\mathbf{b}_h$ :\n",
    "\n",
    "$$\\begin{align}\n",
    "W_h =\n",
    "\\begin{bmatrix} \n",
    "w_{h11} & w_{h12} & w_{h13} \\\\\n",
    "w_{h21} & w_{h22} & w_{h23}\n",
    "\\end{bmatrix}\n",
    "&& \\mathbf{b}_h = \n",
    "\\begin{bmatrix} \n",
    "b_{h1} & b_{h2} & b_{h3}\n",
    "\\end{bmatrix}\n",
    "\\end{align}$$\n",
    "\n",
    "following computation: \n",
    "\n",
    "$$H = \\sigma(X \\cdot W_h + \\mathbf{b}_h) = \\frac{1}{1+e^{-(X \\cdot W_h + \\mathbf{b}_h)}} = \\begin{bmatrix} \n",
    "h_{11} & h_{12} & h_{13} \\\\\n",
    "\\vdots & \\vdots & \\vdots \\\\\n",
    "h_{N1} & h_{N2} & h_{N3}\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "With $\\sigma$ the logistic function, and with $H$ resulting in a $N \\times 3$ matrix.\n",
    "\n",
    "This computation flow is illustrated by the figure below. Each input $x_{ij}$ is multiplied with the weight parameters from the corresponding column $w_{hj1}, w_{hj2}, w_{hj3}$. The multiplication results for each row $k$ ($x_{ij} * w_{hjk}$) are summed to form the $z_{ik}$, after which these are transformed by the logistic function $\\sigma$ to the $h_{ik}$. Note that the bias $B_h$ can be incorporated in $W_h$ by adding a new variable to each input $\\mathbf{x}_i$ that is always $+1$.\n",
    "\n",
    "![Image of the hidden layer computation](https://dl.dropboxusercontent.com/u/8938051/Blog_images/ANN_layer_projection.png)\n",
    "\n",
    "$\\mathbf{b}_h$ and $W_h$ are represented in the code below by `bh` and `Wh` respectively. The hidden layer activations are computed by the `hidden_activations(X, Wh, bh)` method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute activations of output \n",
    "\n",
    "To compute the output activations the hidden layer activations can be projected onto the 2-dimensional output layer. This is done by the $3 \\times 2$ weight matrix $W_o$ ($w_{oij}$ is the weight of the connection between hidden layer neuron $i$ and output activation $j$) and $2 \\times 1$ bias vector $\\mathbf{b}_o$ :\n",
    "\n",
    "$$\\begin{align}\n",
    "W_o =\n",
    "\\begin{bmatrix} \n",
    "w_{o11} & w_{o12} \\\\\n",
    "w_{o21} & w_{o22} \\\\\n",
    "w_{o31} & w_{o32}\n",
    "\\end{bmatrix}\n",
    "&& \\mathbf{b}_o = \n",
    "\\begin{bmatrix} \n",
    "b_{o1} & b_{o2}\n",
    "\\end{bmatrix}\n",
    "\\end{align}$$\n",
    "\n",
    "following computation: \n",
    "\n",
    "$$Y = \\varsigma(H \\cdot W_o + \\mathbf{b}_o)\n",
    "= \\frac{e^{Z_o}}{\\sum_{d=1}^C e^{\\mathbf{z}_{od}}}\n",
    "= \\frac{e^{H \\cdot W_o + \\mathbf{b}_o}}{\\sum_{d=1}^C e^{H \\cdot \\mathbf{w}_{od} + b_{od}}}\n",
    "= \\begin{bmatrix} \n",
    "y_{11} & y_{12}\\\\\n",
    "\\vdots & \\vdots \\\\\n",
    "y_{n1} & y_{n2} \n",
    "\\end{bmatrix}$$\n",
    "\n",
    "With $\\varsigma$ the softmax function, $Y$ resulting in a $n \\times 2$ matrix, $\\mathbf{z}_{od}$ the $d$-th column of the $Z_o$ matrix, $\\mathbf{w}_{od}$ the $d$-th column of the $W_o$ matrix, and $b_{od}$ the $d$-th element of the $b_o$ vector.\n",
    "\n",
    "$\\mathbf{b}_o$ and $W_o$ are represented in the code below by `bo` and `Wo` respectively. The hidden layer activations are computed by the `output_activations(H, Wo, bo)` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define the logistic function\n",
    "def logistic(z): return 1 / (1 + np.exp(-z))\n",
    "\n",
    "# Define the softmax function\n",
    "def softmax(z): return np.exp(z) / np.sum(np.exp(z), axis=1)\n",
    "\n",
    "# Function to compute the hidden activations\n",
    "def hidden_activations(X, Wh, bh):\n",
    "    return logistic(X * Wh + bh)\n",
    "\n",
    "# Define output layer feedforward\n",
    "def output_activations(H, Wo, bo):\n",
    "    return softmax(H * Wo + bo)\n",
    "\n",
    "# Define the neural network function\n",
    "def nn(X, Wh, bh, Wo, bo): \n",
    "    return output_activations(hidden_activations(X, Wh, bh), Wo, bo)\n",
    "\n",
    "# Define the neural network prediction function that only returns\n",
    "#  1 or 0 depending on the predicted class\n",
    "def nn_predict(X, Wh, bh, Wo, bo): \n",
    "    return np.around(nn(X, Wh, bh, Wo, bo))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Vectorization of the backward step\n",
    "\n",
    "#### Vectorization of the output layer backward step\n",
    "\n",
    "##### Compute the error at the output\n",
    "\n",
    "The output layer is a [softmax](http://en.wikipedia.org/wiki/Softmax_function) layer with corresponding [cross-entropy](http://en.wikipedia.org/wiki/Cross_entropy) cost function, which are described in detail in [intermezzo 2]({% post_url 2015-06-10-neural_network_implementation_intermezzo02 %}). The cost function $\\xi$ for $N$ samples and $C$ classes used in this model is defined as:\n",
    "\n",
    "$$\\xi(T,Y) = \\sum_{i=1}^n \\xi(\\mathbf{t}_i,\\mathbf{y}_i) = - \\sum_{i=1}^n \\sum_{i=c}^{C} t_{ic} \\cdot log( y_{ic}) $$\n",
    "\n",
    "The error gradient $\\delta_{o}$ of this cost function at the softmax output layer is simply:\n",
    "\n",
    "$$\\delta_{o} = \\frac{\\partial \\xi}{\\partial Z_o} = Y - T$$\n",
    "\n",
    "With $Z_o$ a $n \\times 2$ matrix of inputs to the softmax layer ($Z_o = H \\cdot W_o + \\mathbf{b}_o$), and $T$ a $n \\times 2$ target matrix that corresponds to $Y$. Note that $\\delta_{o}$ also results in a $n \\times 2$ matrix.\n",
    "\n",
    "$\\delta_{o}$ will be defined in the code as `Eo` and will be computed by the `error_output(Y, T)` method defined below.\n",
    "\n",
    "##### Update the output layer weights\n",
    "At the output the gradient $\\delta_{\\mathbf{w}_{oj}}$ over all $N$ samples is computed by ${\\partial \\xi}/{\\partial \\mathbf{w}_{oj}}$:\n",
    "\n",
    "$$\\frac{\\partial \\xi}{\\partial \\mathbf{w}_{oj}} = \n",
    "\\frac{\\partial Z_{o}}{\\partial \\mathbf{w}_{oj}} \\frac{\\partial Y}{\\partial Z_{o}} \\frac{\\partial \\xi}{\\partial Y} = \n",
    "\\frac{\\partial Z_{o}}{\\partial w_{oji}} \\frac{\\partial \\xi}{\\partial Z_o} =\n",
    "\\sum_{i=1}^N h_{ij} (\\mathbf{y}_i - \\mathbf{t}_i) = \n",
    "\\sum_{i=1}^N h_{ij} \\delta_{oi}$$\n",
    "\n",
    "With $\\mathbf{w}_{oj}$ the $j$-th row of $W_o$ and thus a $1 \\times 2$ vector. This formula can be written out as matrix operations with the parameters of the output layer:\n",
    "\n",
    "$$\\frac{\\partial \\xi}{\\partial W_o} = H^T \\cdot (Y-T) = H^T \\cdot \\delta_{o}$$\n",
    "\n",
    "The resulting gradient is a $3 \\times 2$ [Jacobian matrix](http://en.wikipedia.org/wiki/Jacobian_matrix_and_determinant):\n",
    "\n",
    "$$J_{W_o} = \\frac{\\partial \\xi}{\\partial W_o} =\n",
    "\\begin{bmatrix} \n",
    "\\frac{\\partial \\xi}{\\partial w_{o11}} & \\frac{\\partial \\xi}{\\partial w_{o12}} \\\\\n",
    "\\frac{\\partial \\xi}{\\partial w_{o21}} & \\frac{\\partial \\xi}{\\partial w_{o22}} \\\\\n",
    "\\frac{\\partial \\xi}{\\partial w_{o31}} & \\frac{\\partial \\xi}{\\partial w_{o32}}\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "$J_{W_o}$ will be defined in the code as `JWo` and will be computed by the `gradient_weight_out(H, Eo)` method defined below.\n",
    "\n",
    "\n",
    "##### Update the output layer bias\n",
    "The bias $\\mathbf{b}_o$ can be updated in the same manner. The formula to compute the gradient ${\\partial \\xi}/{\\partial \\mathbf{b}_{o}}$ for batch processing over all $N$ samples is:\n",
    "\n",
    "$$\\frac{\\partial \\xi}{\\partial \\mathbf{b}_{o}} = \\frac{\\partial Z_{o}}{\\partial \\mathbf{b}_{o}} \\frac{\\partial Y}{\\partial Z_{o}} \\frac{\\partial \\xi}{\\partial Y} = \\sum_{i=1}^N 1 * (\\mathbf{y}_i - \\mathbf{t}_i) = \\sum_{i=1}^N \\delta_{oi}$$\n",
    "\n",
    "The resulting gradient is a $2 \\times 1$ Jacobian matrix:\n",
    "\n",
    "$$J_{b_o} = \\frac{\\partial \\xi}{\\partial \\mathbf{b}_o} =\n",
    "\\begin{bmatrix} \n",
    "\\frac{\\partial \\xi}{\\partial b_{o1}} & \\frac{\\partial \\xi}{\\partial b_{o2}}\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "$J_{b_o}$ will be defined in the code as `Jbo` and will be computed by the `gradient_bias_out(Eo)` method defined below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the cost function\n",
    "def cost(Y, T):\n",
    "    return - np.multiply(T, np.log(Y)).sum()\n",
    "\n",
    "# Define the error function at the output\n",
    "def error_output(Y, T):\n",
    "    return Y - T\n",
    "\n",
    "# Define the gradient function for the weight parameters at the output layer\n",
    "def gradient_weight_out(H, Eo): \n",
    "    return  H.T * Eo\n",
    "\n",
    "# Define the gradient function for the bias parameters at the output layer\n",
    "def gradient_bias_out(Eo): \n",
    "    return  np.sum(Eo, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorization of the hidden layer backward step\n",
    "\n",
    "##### Compute the error at the hidden layer\n",
    "\n",
    "The error gradient $\\delta_{h}$ of the cost function at the hidden layer is defined as:\n",
    "\n",
    "$$\\delta_{h} = \\frac{\\partial \\xi}{\\partial Z_h} = \\frac{\\partial H}{\\partial Z_h} \\frac{\\partial \\xi}{\\partial H} = \\frac{\\partial H}{\\partial Z_h} \\frac{\\partial Z_o}{\\partial H} \\frac{\\partial \\xi}{\\partial Z_o}$$\n",
    "\n",
    "With $Z_h$ a $n \\times 3$ matrix of inputs to the logistic functions in the hidden neurons ($Z_h = X \\cdot W_h + \\mathbf{b}_h$). Note that $\\delta_{h}$ will also result in a $N \\times 3$ matrix.\n",
    "\n",
    "Lets first derive the error gradient $\\delta_{hij}$ for one sample $i$ at hidden neuron $j$. The gradients that backpropagate from the previous layer via the weighted connections are summed for each origin $h_{ij}$. \n",
    "\n",
    "$$\\delta_{hij} = \\frac{\\partial \\xi}{\\partial z_{hij}} \n",
    "= \\frac{\\partial h_{ij}}{\\partial z_{hij}} \\frac{\\partial \\mathbf{z}_{oi}}{\\partial h_{ij}} \\frac{\\partial \\xi}{\\partial \\mathbf{z}_{oi}} \n",
    "= h_{ij} (1-h_{ij}) \\sum_{k=1}^2 w_{ojk} (y_{ik}-t_{ik})\n",
    "= h_{ij} (1-h_{ij}) [\\delta_{oi} \\cdot \\mathbf{w}_{oj}^T]$$\n",
    "\n",
    "Where $\\mathbf{w}_{oj}$ is the $j$-th row of $W_o$, and thus a $1 \\times 2$ vector and $\\delta_{oi}$ is a $1 \\times 2$ vector. The full $N \\times 3$ error matrix $\\delta_{h}$ can thus be calculated as:\n",
    "\n",
    "$$\\delta_{h} = \\frac{\\partial \\xi}{\\partial Z_h} = H \\circ (1 - H) \\circ [\\delta_{o} \\cdot W_o^T]$$\n",
    "\n",
    "With $\\circ$ the [elementwise product](http://en.wikipedia.org/wiki/Hadamard_product_%28matrices%29). \n",
    "\n",
    "$\\delta_{h}$ will be defined in the code as `Eh` and will be computed by the `error_hidden(H, Wo, Eo)` method defined below.\n",
    "\n",
    "\n",
    "##### Update the hidden layer weights\n",
    "At the hidden layer the gradient ${\\partial \\xi}/{\\partial \\mathbf{w}_{hj}}$ over all $N$ samples can be computed by:\n",
    "\n",
    "$$\\frac{\\partial \\xi}{\\partial \\mathbf{w}_{hj}} = \n",
    "\\frac{\\partial Z_{h}}{\\partial \\mathbf{w}_{hj}} \\frac{\\partial H}{\\partial Z_{h}} \\frac{\\partial \\xi}{\\partial H} = \n",
    "\\frac{\\partial Z_{h}}{\\partial \\mathbf{w}_{hj}} \\frac{\\partial \\xi}{\\partial Z_h} =\n",
    "\\sum_{i=1}^N x_{ij} \\delta_{hi}$$\n",
    "\n",
    "With $\\mathbf{w}_{hj}$ the $j$-th row of $W_h$ and thus a $1 \\times 3$ vector.  We can write this formula out as matrix operations with the parameters of the hidden layer:\n",
    "\n",
    "$$\\frac{\\partial \\xi}{\\partial W_h} = X^T \\cdot \\delta_{h}$$\n",
    "\n",
    "The resulting gradient is a $2 \\times 3$ [Jacobian matrix](http://en.wikipedia.org/wiki/Jacobian_matrix_and_determinant):\n",
    "\n",
    "$$J_{W_h} = \\frac{\\partial \\xi}{\\partial W_{h}} =\n",
    "\\begin{bmatrix} \n",
    "\\frac{\\partial \\xi}{\\partial w_{h11}} & \\frac{\\partial \\xi}{\\partial w_{h12}} & \\frac{\\partial \\xi}{\\partial w_{h13}} \\\\\n",
    "\\frac{\\partial \\xi}{\\partial w_{h21}} & \\frac{\\partial \\xi}{\\partial w_{h22}} & \\frac{\\partial \\xi}{\\partial w_{h23}} \\\\\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "$J_{W_h}$ will be defined in the code as `JWh` and will be computed by the `gradient_weight_hidden(X, Eh)` method defined below.\n",
    "\n",
    "##### Update the hidden layer bias\n",
    "The bias $\\mathbf{b}_h$ can be updated in the same manner. The formula to compute the gradient ${\\partial \\xi}/{\\partial \\mathbf{b}_{h}}$ for batch processing over all $N$ samples is:\n",
    "\n",
    "$$\\frac{\\partial \\xi}{\\partial \\mathbf{b}_{h}} = \\frac{\\partial Z_{h}}{\\partial \\mathbf{b}_{h}} \\frac{\\partial H}{\\partial Z_{h}} \\frac{\\partial \\xi}{\\partial H}\n",
    "= \\sum_{j=1}^N \\delta_{hj}$$\n",
    "\n",
    "The resulting gradient is a $1 \\times 3$ Jacobian matrix:\n",
    "\n",
    "$$J_{b_h} = \\frac{\\partial \\xi}{\\partial \\mathbf{b}_{h}} =\n",
    "\\begin{bmatrix} \n",
    "\\frac{\\partial \\xi}{\\partial b_{h1}} & \\frac{\\partial \\xi}{\\partial b_{h2}} & \\frac{\\partial \\xi}{\\partial b_{h3}}\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "$J_{b_h}$ will be defined in the code as `Jbh` and will be computed by the `gradient_bias_hidden(Eh)` method defined below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define the error function at the hidden layer\n",
    "def error_hidden(H, Wo, Eo):\n",
    "    # H * (1-H) * (E . Wo^T)\n",
    "    return np.multiply(np.multiply(H,(1 - H)), Eo.dot(Wo.T))\n",
    "\n",
    "# Define the gradient function for the weight parameters at the hidden layer\n",
    "def gradient_weight_hidden(X, Eh):\n",
    "    return X.T * Eh\n",
    "\n",
    "# Define the gradient function for the bias parameters at the output layer\n",
    "def gradient_bias_hidden(Eh): \n",
    "    return  np.sum(Eh, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient checking\n",
    "\n",
    "Programming the computation of the backpropagation gradient is prone to bugs. This is why it is recommended to [check the gradients](http://ufldl.stanford.edu/wiki/index.php/Gradient_checking_and_advanced_optimization) of your models. Gradient checking is done by computing the [numerical gradient](http://en.wikipedia.org/wiki/Numerical_differentiation) of each parameter, and compare this value to the gradient found by backpropagation.\n",
    "\n",
    "The numerical gradient ${\\partial \\xi}/{\\partial \\theta_i}$ for a parameter $\\theta_i$ can be computed by:\n",
    "\n",
    "$$\\frac{\\partial \\xi}{\\partial \\theta_i}\n",
    "= \\frac{f(X, \\theta_1, \\cdots, \\theta_i+\\epsilon, \\cdots, \\theta_m) - f(X, \\theta_1, \\cdots, \\theta_i-\\epsilon, \\cdots, \\theta_m)}{2\\epsilon}$$\n",
    "\n",
    "Where $f$ if the neural network function that takes the input $X$ and all parameters $\\theta$, and $\\epsilon$ is the small change that is used to peturbate the parameter $\\theta_i$. \n",
    "\n",
    "The numerical gradient for each parameter should be close to the backpropagation gradient for that parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialize weights and biases\n",
    "init_var = 1\n",
    "# Initialize hidden layer parameters\n",
    "bh = np.random.randn(1, 3) * init_var\n",
    "Wh = np.random.randn(2, 3) * init_var\n",
    "# Initialize output layer parameters\n",
    "bo = np.random.randn(1, 2) * init_var\n",
    "Wo = np.random.randn(3, 2) * init_var\n",
    "\n",
    "# Compute the gradients by backpropagation\n",
    "# Compute the activations of the layers\n",
    "H = hidden_activations(X, Wh, bh)\n",
    "Y = output_activations(H, Wo, bo)\n",
    "# Compute the gradients of the output layer\n",
    "Eo = error_output(Y, T)\n",
    "JWo = gradient_weight_out(H, Eo)\n",
    "Jbo = gradient_bias_out(Eo)\n",
    "# Compute the gradients of the hidden layer\n",
    "Eh = error_hidden(H, Wo, Eo)\n",
    "JWh = gradient_weight_hidden(X, Eh)\n",
    "Jbh = gradient_bias_hidden(Eh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Combine all parameter matrices in a list\n",
    "params = [Wh, bh, Wo, bo]\n",
    "# Combine all parameter gradients in a list\n",
    "grad_params = [JWh, Jbh, JWo, Jbo]\n",
    "\n",
    "# Set the small change to compute the numerical gradient\n",
    "eps = 0.0001\n",
    "\n",
    "# Check each parameter matrix\n",
    "for p_idx in range(len(params)):\n",
    "    # Check each parameter in each parameter matrix\n",
    "    for row in range(params[p_idx].shape[0]):\n",
    "        for col in range(params[p_idx].shape[1]):\n",
    "            # Copy the parameter matrix and change the current parameter slightly\n",
    "            p_matrix_min = params[p_idx].copy()\n",
    "            p_matrix_min[row,col] -= eps\n",
    "            p_matrix_plus = params[p_idx].copy()\n",
    "            p_matrix_plus[row,col] += eps\n",
    "            # Copy the parameter list, and change the updated parameter matrix\n",
    "            params_min = params[:]\n",
    "            params_min[p_idx] = p_matrix_min\n",
    "            params_plus = params[:]\n",
    "            params_plus[p_idx] =  p_matrix_plus\n",
    "            # Compute the numerical gradient\n",
    "            grad_num = (cost(nn(X, *params_plus), T)-cost(nn(X, *params_min), T))/(2*eps)\n",
    "            print('backprop gradient: {:.6f} ; numerical gradient {:.6f}'.format(grad_params[p_idx][row,col], grad_num))\n",
    "            # Raise error if the numerical grade is not close to the backprop gradient\n",
    "            if not np.isclose(grad_num, grad_params[p_idx][row,col]):\n",
    "                raise ValueError('Numerical gradient is not close to the backpropagation gradient!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backpropagation updates\n",
    "\n",
    "In the previous examples we used simple [gradient decent](http://en.wikipedia.org/wiki/Gradient_descent) to optimize the parameters with respect to the cost function (which was [convex](http://en.wikipedia.org/wiki/Convex_function) in the [first]({% post_url 2015-06-10-neural_network_implementation_part01 %}) and [second]({% post_url 2015-06-10-neural_network_implementation_part02 %}) example). Multilayer neural networks with non-linear activation functions and many parameters are highly unlikely to have convex cost functions. Simple  gradient decent is not the best method to find a global minimum of a non-convex cost function since it is a [local optimization](http://en.wikipedia.org/wiki/Local_search_%28optimization%29) method that tends to converge to a [local minimum](http://en.wikipedia.org/wiki/Local_optimum).\n",
    "\n",
    "To solve this issue this example uses a variant of gradient decent called [momentum](http://www.willamette.edu/~gorr/classes/cs449/momrate.html). The method of momentum can be visualized as a ball rolling down the surface of the cost function, this ball will increase in velocity while rolling downhill, and will decrease in velocity when rolling uphill. This momentum update is formulated as:\n",
    "\n",
    "$$\\begin{split}\n",
    "V(k+1) & = \\lambda V(k) - \\mu \\frac{\\partial \\xi}{\\partial \\theta(k)} \\\\\n",
    "\\theta(k+1) & = \\theta(k) + V(k+1)\n",
    "\\end{split}$$\n",
    "\n",
    "Where $V(k)$ is the velocity of the parameters at iteration $k$, $\\theta(k)$ is the location of the parameters at iteration $k$, ${\\partial \\xi}/{\\partial \\theta(k)}$ the gradient of the parameters with respect to the cost function at iteration $k$, $\\lambda$ how much the velocity decreases due to 'resistance' and $\\mu$ the learning rate (how much the gradient affects the velocity).\n",
    "\n",
    "The velocities $V_{W_h}, V_{\\mathbf{b}_h}, V_{W_o}, V_{\\mathbf{b}_o},$ corresponding to the parameters $ W_h, \\mathbf{b}_h, W_o, \\mathbf{b}_o$ are represented in the code by `VWh`, `Vbh`, `VWo`, `Vbo`. And kept in a list `Vs`. They are updated by the `update_velocity(X, T, ls_of_params, Vs, momentum_term, learning_rate)` method. After updating the velocities the parameters are updated via the `update_params(ls_of_params, Vs)` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the update function to update the network parameters over 1 iteration\n",
    "def backprop_gradients(X, T, Wh, bh, Wo, bo):\n",
    "    # Compute the output of the network\n",
    "    # Compute the activations of the layers\n",
    "    H = hidden_activations(X, Wh, bh)\n",
    "    Y = output_activations(H, Wo, bo)\n",
    "    # Compute the gradients of the output layer\n",
    "    Eo = error_output(Y, T)\n",
    "    JWo = gradient_weight_out(H, Eo)\n",
    "    Jbo = gradient_bias_out(Eo)\n",
    "    # Compute the gradients of the hidden layer\n",
    "    Eh = error_hidden(H, Wo, Eo)\n",
    "    JWh = gradient_weight_hidden(X, Eh)\n",
    "    Jbh = gradient_bias_hidden(Eh)\n",
    "    return [JWh, Jbh, JWo, Jbo]\n",
    "\n",
    "def update_velocity(X, T, ls_of_params, Vs, momentum_term, learning_rate):\n",
    "    # ls_of_params = [Wh, bh, Wo, bo]\n",
    "    # Js = [JWh, Jbh, JWo, Jbo]\n",
    "    Js = backprop_gradients(X, T, *ls_of_params)\n",
    "    return [momentum_term * V - learning_rate * J for V,J in zip(Vs, Js)]\n",
    "\n",
    "def update_params(ls_of_params, Vs):\n",
    "    # ls_of_params = [Wh, bh, Wo, bo]\n",
    "    # Vs = [VWh, Vbh, VWo, Vbo]\n",
    "    return [P + V for P,V in zip(ls_of_params, Vs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the neural network model with this momentum method over $300$ iterations on the dataset $X$ and $T$ defined in the beginning results in the training convergence plotted in the figure below. This smooth convergence would almost never result from simple gradient descent. You can try it out yourself and implement gradient descent optimization for this model. You will notice that if you run your gradient descent a couple of times from different starting points that it will almost always converge to a sub-optimal solution. Note that momentum is less sensitive to the learning rate than gradient descent, but the learning rate hyperparameter still needs to be tuned separately. In this tutorial, this learning rate was tuned by experimentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run backpropagation\n",
    "# Initialize weights and biases\n",
    "init_var = 0.1\n",
    "# Initialize hidden layer parameters\n",
    "bh = np.random.randn(1, 3) * init_var\n",
    "Wh = np.random.randn(2, 3) * init_var\n",
    "# Initialize output layer parameters\n",
    "bo = np.random.randn(1, 2) * init_var\n",
    "Wo = np.random.randn(3, 2) * init_var\n",
    "# Parameters are already initilized randomly with the gradient checking\n",
    "# Set the learning rate\n",
    "learning_rate = 0.02\n",
    "momentum_term = 0.9\n",
    "\n",
    "# define the velocities Vs = [VWh, Vbh, VWo, Vbo]\n",
    "Vs = [np.zeros_like(M) for M in [Wh, bh, Wo, bo]]\n",
    "\n",
    "# Start the gradient descent updates and plot the iterations\n",
    "nb_of_iterations = 300  # number of gradient descent updates\n",
    "lr_update = learning_rate / nb_of_iterations # learning rate update rule\n",
    "ls_costs = []  # list of cost over the iterations\n",
    "for i in range(nb_of_iterations):\n",
    "    # Add the current cost to the cost list\n",
    "    current_cost = cost(nn(X, Wh, bh, Wo, bo), T)\n",
    "    ls_costs.append(current_cost)\n",
    "    Vs = update_velocity(X, T, [Wh, bh, Wo, bo], Vs, momentum_term, learning_rate)\n",
    "    Wh, bh, Wo, bo = update_params([Wh, bh, Wo, bo], Vs)\n",
    "\n",
    "# Add the final cost to the cost list\n",
    "ls_costs.append(cost(nn(X, Wh, bh, Wo, bo), T))\n",
    "# Plot the cost over the iterations\n",
    "plt.plot(ls_costs, 'b-')\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('$\\\\xi$', fontsize=15)\n",
    "plt.title('Decrease of cost over backprop iteration')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of the trained classifier\n",
    "\n",
    "\n",
    "The resulting decision boundary of running backpropagation with momentum on the example inputs $X$ and targets $T$ is shown in the figure below. The background color (blue, red) refers to the classification decision of the trained classifier at that position in the input space. Note that the classifier is able to surround the blue samples and that all examples are classified correctly by the trained classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot the resulting decision boundary\n",
    "# Generate a grid over the input space to plot the color of the\n",
    "#  classification at that grid point\n",
    "nb_of_xs = 200\n",
    "xs1 = np.linspace(-2, 2, num=nb_of_xs)\n",
    "xs2 = np.linspace(-2, 2, num=nb_of_xs)\n",
    "xx, yy = np.meshgrid(xs1, xs2) # create the grid\n",
    "# Initialize and fill the classification plane\n",
    "classification_plane = np.zeros((nb_of_xs, nb_of_xs))\n",
    "for i in range(nb_of_xs):\n",
    "    for j in range(nb_of_xs):\n",
    "        pred = nn_predict(np.asmatrix([xx[i,j], yy[i,j]]), Wh, bh, Wo, bo)\n",
    "        classification_plane[i,j] = pred[0,0]\n",
    "# Create a color map to show the classification colors of each grid point\n",
    "cmap = ListedColormap([\n",
    "        colorConverter.to_rgba('r', alpha=0.30),\n",
    "        colorConverter.to_rgba('b', alpha=0.30)])\n",
    "\n",
    "# Plot the classification plane with decision boundary and input samples\n",
    "plt.contourf(xx, yy, classification_plane, cmap=cmap)\n",
    "# Plot both classes on the x1, x2 plane\n",
    "plt.plot(x_red[:,0], x_red[:,1], 'ro', label='class red')\n",
    "plt.plot(x_blue[:,0], x_blue[:,1], 'bo', label='class blue')\n",
    "plt.grid()\n",
    "plt.legend(loc=2)\n",
    "plt.xlabel('$x_1$', fontsize=15)\n",
    "plt.ylabel('$x_2$', fontsize=15)\n",
    "plt.axis([-2, 2, -2, 2])\n",
    "plt.title('red vs blue classification boundary')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation of the input domain\n",
    "\n",
    "There are two reasons why the neural network is able to separate the non-linearly separable classes. First of all the non-linear logistic functions in the hidden layer can help to make non-linear transformations of the data. And second the hidden layer contains three dimensions. By projecting the 2-dimensional input data to 3 dimensions, the classes can become linearly separable in this 3-dimensional space. This projection in illustrated in the figure below that plots the transformations of the input samples upon this 3-dimensional hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define the projections of the blue and red classes\n",
    "H_blue = hidden_activations(x_blue, Wh, bh)\n",
    "H_red = hidden_activations(x_red, Wh, bh)\n",
    "\n",
    "# Plot the error surface\n",
    "fig = plt.figure()\n",
    "ax = Axes3D(fig)\n",
    "ax.plot(np.ravel(H_blue[:,0]), np.ravel(H_blue[:,1]), np.ravel(H_blue[:,2]), 'bo')\n",
    "ax.plot(np.ravel(H_red[:,0]), np.ravel(H_red[:,1]), np.ravel(H_red[:,2]), 'ro')\n",
    "ax.set_xlabel('$h_1$', fontsize=15)\n",
    "ax.set_ylabel('$h_2$', fontsize=15)\n",
    "ax.set_zlabel('$h_3$', fontsize=15)\n",
    "ax.view_init(elev=10, azim=-40)\n",
    "plt.title('Projection of the input X onto the hidden layer H')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This post at [peterroelants.github.io](http://peterroelants.github.io/) is generated from an IPython notebook file. [Link to the full IPython notebook file](https://github.com/peterroelants/peterroelants.github.io/blob/master/notebooks/neural_net_implementation/neural_network_implementation_part04.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
